---
title: "Kaplan's in-class notes for 2025-02-10"
date: 2025-02-10
---

```{r include=FALSE}
library(LSTbook)
```

## Rosling Ch. 3 *The straight-line instinct*

Interpolation and extrapolation. Why extrapolation is hard. Why linear interpolation is good.



## Regression techniques

## Computing

Contrast prediction with regression: Same model training, but different goal: to understand what the connections are in a system.

- Different criteria apply to the selection of explanatory variables.
- We are interested in details of the model, not just the prediction. But the form will look much like he prediction interval for quantitative response variables.

```{webr-r}
Galton |>
  point_plot(height ~ mother + 1 + sex, annot = "model", interval = "prediction")
```

- Show also "confidence band"

```{r}
Hmod1 <- Galton |>
  model_train(height ~ mother + father + sex) 
Hmod1 |> conf_interval()
Hmod1 |> 
  model_eval(Galton) |>
  summarize(sd(.resid))
```


###  Evaluation of model formula

Compare by-hand evaluation at given inputs 

### Why do statistics book defer prediction intervals?

Why statistics books teach confidence intervals *before* prediction intervals: Prediction intervals look bad.

- The residuals set the size (mainly) of the prediction intervals.
- The prediction bands cover about 95% of the data. Drawing them by hand from a point plot.

Confidence intervals get smaller/tighter the more data you have.

Simulation: We'll simulate the height data so that we can generate as much (made-up) data as we like.

```{r}
Galton |> 
  summarize(mean(mother), sd(mother), 
            mean(father), sd(father))
```


```{r}
Hsim <- datasim_make(
  mom <- rnorm(n, mean=64, sd = 2.3),
  dad <- rnorm(n, mean=69, sd = 2.5),
  sex <- categorical(n, "b", "g"),
  height <- 15.34 + 0.32*mom + 0.41*dad + 
    cat2value(sex, b=5.22, g = 0) +
    2.15 * rnorm(n)
)
Hsim |> take_sample(n = 5)
```


Prediction intervals don't change so much with sample size:

```{r}
Hsim |> 
  take_sample(n = 100) |>
  point_plot(height ~ mom, annot = "model", interval = "prediction")
Hsim |> 
  take_sample(n = 10000) |>
  point_plot(height ~ mom, annot = "model", interval = "prediction")
```

Now change the interval to `"confidence"` and see how nice the graph looks.


## R^2^

Another model summary: How much of the variation in the response variable has been explained.

```{r}
Hmod1 |> R2()
```

## Covariates

Show coefficients change as we add in covariates:

```{r}
Galton |> 
  model_train(height ~ mother) |>
  conf_interval()
Galton |> 
  model_train(height ~ mother + father + sex) |>
  conf_interval()
```

The coefficient tells the contribution of its variable *in the context of* the other explanatory variable.

A more dramatic example:

In class I asked you what states have the highest SAT scores on average. Someone suggested that two top states might be California and Massachusetts.

In the spirit of Rosler, let's look at the data:

```{r}
SAT |> 
  select(state, sat) |>
  arrange(desc(sat)) |>
  head(10)
```

Look at the worst states. How should I modify the command?

```{r}
SAT |>
  select(state, sat) |>
  filter(state %in% c("California", "Massachusetts"))
```

Let's look at some explanatory variables that might account for SAT score: expenditures, class size, teacher salaries, ???

```{r}
SAT |> 
  model_train(sat ~ expend) |>
  conf_interval()
```

Interpret the coefficient. "Effect size" but don't necessarily put a causal interpretation on it.

A covariate: class size?

```{r}
SAT |> 
  model_train(sat ~ expend + ratio) |>
  conf_interval()
```


Two graphs:

```{r}
SAT |>
  point_plot(sat ~ expend, annot = "model")
SAT |>
  point_plot(sat ~ expend + frac, annot = "model")
```

The second plot looks at the relationship between expenditure and SAT scores, **adjusting for** the fraction of students who take the SAT.



-----

MOVE THIS TO HYPOTHESIS TESTING when those note files have been created.


An article about reporting baseline characteristics in clinical trials, arguing that to avoid the trade-off between a data-mining kind of choice of covariates and not including them as needed, best just to plan for adjustment and do it without looking at the baseline balance. Maybe something for hypothesis-testing section: https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4780131703

